{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.93      1233\n",
      "           1       0.70      0.34      0.46       237\n",
      "\n",
      "    accuracy                           0.87      1470\n",
      "   macro avg       0.79      0.66      0.69      1470\n",
      "weighted avg       0.85      0.87      0.85      1470\n",
      "\n",
      "Data accuracy on only new samples:  0.8740740740740741\n",
      "Data accuracy on all samples:  0.8700680272108844\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import all_estimators\n",
    "from time import time\n",
    "import scipy.stats as stats\n",
    "from sklearn.utils.fixes import loguniform\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "df = pd.read_csv(r'data/data_processed.csv')\n",
    "df_continous = pd.read_csv(r'data/data_continous.csv')\n",
    "df_categorical = pd.read_csv(r'data/data_categorical.csv')\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# copying job satisfaction into new array\n",
    "JAtt = df['Attrition'].values\n",
    "\n",
    "df_good = pd.concat([df_categorical, df[\"MonthlyIncome\"], df[\"BusinessTravel\"], df[\"StockOptionLevel\"], df[\"DistanceFromHome\"]], axis=1)\n",
    "df = df_good.drop(['Attrition'], axis=1)\n",
    "\n",
    "# splitting inputs by row index\n",
    "# all data\n",
    "df_training = df.iloc[:1200,:]\n",
    "df_validation = df.iloc[1200:,:]\n",
    "# continous data\n",
    "df_training_continous = df_continous.iloc[:1200,:]\n",
    "df_validation_continous = df_continous.iloc[1200:,:]\n",
    "# categorical data\n",
    "df_training_categorical = df_categorical.iloc[:1200,:]\n",
    "df_validation_categorical = df_categorical.iloc[1200:,:]\n",
    "# splitting outputs by number\n",
    "JAtt_training = JAtt[:1200]\n",
    "JAtt_validation = JAtt[1200:]\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "\n",
    "# data classifier\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "\n",
    "clf.fit(df_training,JAtt_training)\n",
    "acc = clf.score(df_validation, JAtt_validation)\n",
    "acc_all = clf.score(df, JAtt)\n",
    "\n",
    "pred = clf.predict(df)\n",
    "\n",
    "print(classification_report(JAtt, pred))\n",
    "\n",
    "# print results\n",
    "print('Data accuracy on only new samples: ', acc)\n",
    "print('Data accuracy on all samples: ', acc_all)\n",
    "\n",
    "# print(allColumnsNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomized search\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results[\"rank_test_score\"] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\n",
    "                \"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                    results[\"mean_test_score\"][candidate],\n",
    "                    results[\"std_test_score\"][candidate],\n",
    "                )\n",
    "            )\n",
    "            print(\"Parameters: {0}\".format(results[\"params\"][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\n",
    "    \"solver\": [\"svd\", \"lsqr\", \"eigen\"],\n",
    "    \"shrinkage\": [None, 'auto'],\n",
    "    \"tol\": np.power(10, np.arange(-6, -4, dtype=float))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run randomized search\n",
    "n_iter_search = 150\n",
    "random_search = RandomizedSearchCV(\n",
    "    clf, param_distributions=param_dist, n_iter=n_iter_search\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siman\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:306: UserWarning: The total space of parameters 12 is smaller than n_iter=1500. Running 12 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 0.61 seconds for 1500 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.860 (std: 0.013)\n",
      "Parameters: {'tol': 1e-06, 'solver': 'svd', 'shrinkage': None}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.860 (std: 0.013)\n",
      "Parameters: {'tol': 1e-05, 'solver': 'svd', 'shrinkage': None}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.860 (std: 0.013)\n",
      "Parameters: {'tol': 1e-06, 'solver': 'lsqr', 'shrinkage': None}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.860 (std: 0.013)\n",
      "Parameters: {'tol': 1e-05, 'solver': 'lsqr', 'shrinkage': None}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.860 (std: 0.013)\n",
      "Parameters: {'tol': 1e-06, 'solver': 'lsqr', 'shrinkage': 'auto'}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.860 (std: 0.013)\n",
      "Parameters: {'tol': 1e-05, 'solver': 'lsqr', 'shrinkage': 'auto'}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.860 (std: 0.013)\n",
      "Parameters: {'tol': 1e-06, 'solver': 'eigen', 'shrinkage': 'auto'}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.860 (std: 0.013)\n",
      "Parameters: {'tol': 1e-05, 'solver': 'eigen', 'shrinkage': 'auto'}\n",
      "\n",
      "GridSearchCV took 0.14 seconds for 4 candidate parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.860 (std: 0.013)\n",
      "Parameters: {'shrinkage': None, 'tol': 1e-06}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.860 (std: 0.013)\n",
      "Parameters: {'shrinkage': None, 'tol': 1e-05}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: nan (std: nan)\n",
      "Parameters: {'shrinkage': 'auto', 'tol': 1e-06}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siman\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "20 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\siman\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\siman\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 605, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"c:\\Users\\siman\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 445, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"c:\\Users\\siman\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 580, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 18 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\siman\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\siman\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 605, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"c:\\Users\\siman\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 445, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"c:\\Users\\siman\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 580, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 19 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\siman\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\siman\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 589, in fit\n",
      "    raise NotImplementedError(\"shrinkage not supported\")\n",
      "NotImplementedError: shrinkage not supported\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\siman\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.86 0.86 0.86 0.86  nan  nan  nan  nan 0.86 0.86 0.86 0.86]\n",
      "  warnings.warn(\n",
      "c:\\Users\\siman\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "10 fits failed out of a total of 20.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\siman\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\siman\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 589, in fit\n",
      "    raise NotImplementedError(\"shrinkage not supported\")\n",
      "NotImplementedError: shrinkage not supported\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\siman\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.86 0.86  nan  nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "random_search.fit(df_training, JAtt_training)\n",
    "print(\n",
    "    \"RandomizedSearchCV took %.2f seconds for %d candidates parameter settings.\"\n",
    "    % ((time() - start), n_iter_search)\n",
    ")\n",
    "report(random_search.cv_results_)\n",
    "\n",
    "# use a full grid over all parameters\n",
    "param_grid = {\n",
    "    # \"shrinkage\": np.concatenate([[None, 'auto'], np.linspace(1e-7,1, num=100),], axis=0),\n",
    "    \"shrinkage\": [None, 'auto'],\n",
    "    \"tol\": np.power(10, np.arange(-6, -4, dtype=float)),\n",
    "}\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
    "start = time()\n",
    "grid_search.fit(df_training, JAtt_training)\n",
    "\n",
    "print(\n",
    "    \"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "    % (time() - start, len(grid_search.cv_results_[\"params\"]))\n",
    ")\n",
    "report(grid_search.cv_results_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3c6a3af7cc3dd87b1c9aec9c941132942751acefef11dd989f38e57e7ca82ce1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
